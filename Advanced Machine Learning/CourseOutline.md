# Advanced Machine Learning Course

In previous courses, we have studied how to build a predictive model for different scenarios.

- Can we combine the decisions from multiple models to make better predictions?  
- For data where one of the target classes has a higher ratio compared to the other(s), how do we ensure that the model performs well?  
- How to optimize a model's performance to ensure that it aligns with the business objective we want to achieve?  

Improving a model's performance is key to achieving business outcomes, and we can do so by leveraging **model ensembles** and **model tuning techniques**.

---

## üß† Overview

Ensemble models use a collection of machine learning models and leverage techniques like **bagging**, **boosting**, and **stacking** to make predictions. They can be used across a wide variety of classification and regression problems.

To maximize a model's performance, we first need a clear picture of how it's performing. **Cross-validation** helps us better use our data to obtain this picture. Once we have that, we can apply **hyperparameter tuning** to optimize model performance and make more accurate predictions.

When dealing with **imbalanced datasets**‚Äîwhere one class significantly outnumbers the others‚Äîit‚Äôs crucial to apply specialized techniques. In many real-world business cases, identifying the minority class can have greater value than simply maximizing overall accuracy.

This course covers:
- Ensemble Methods
- Cross-Validation
- Hyperparameter Tuning
- Handling Imbalanced Data

These techniques help enhance predictive modeling expertise and achieve better outcomes.

---

## üéØ Course Objectives

After completing this course, you will be able to:

- ‚úÖ Use ensemble techniques to improve predictability and enhance model robustness  
- ‚úÖ Focus on problem recognition and build predictive models in business contexts  
- ‚úÖ Use cross-validation to evaluate model performance more effectively  
- ‚úÖ Improve model performance through hyperparameter tuning techniques  
- ‚úÖ Handle class imbalance to reduce bias and align model output with business needs  

---

## üìö Topics Covered

| Week | Module                  | Topics Covered                                                                 |
|------|-------------------------|--------------------------------------------------------------------------------|
| 1    | Bagging and Random Forest | - Introduction to Ensemble Techniques<br>- Introduction to Bagging<br>- Sampling with Replacement<br>- Introduction to Random Forest |
| 2    | Boosting                | - Introduction to Boosting<br>- Boosting Algorithms<br>- Adaboost<br>- Gradient Boosting<br>- XGBoost<br>- Stacking |
| 3    | Model Tuning            | - Cross-validation<br>- Oversampling and Undersampling<br>- Model Tuning and Performance<br>- Hyperparameter Tuning<br>- Grid Search<br>- Random Search |

---

## üéì Learning Materials

| Week | Module                  | No. of Videos | Total Duration | Understanding Quizzes | Graded Quizzes | Practice Assignments |
|------|-------------------------|----------------|----------------|------------------------|----------------|-----------------------|
| 1    | Bagging and Random Forest | 5              | ~1.5 hours     | 5                      | 1              | 1                     |
| 2    | Boosting                | 7              | ~1.5 hours     | 7                      | 1              | 1                     |
| 3    | Model Tuning            | 9              | ~2 hours       | 9                      | 1              | 1                     |

---

## üõ†Ô∏è Project

At the end of the course, a **graded hands-on project** must be submitted.

You will apply all learned techniques to:
- Standardize the modeling process
- Handle class imbalance
- Tune hyperparameters

**Project Objective:** Help a bank predict which customers are likely to renounce their credit card services.
